{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llm/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "/opt/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append('../src')\n",
    "import config\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = utils.get_raw_dataset()\n",
    "df = utils.filter_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only needs to be run once. after completed run, update config file with your model path\n",
    "# model_path = utils.get_gguf_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M1) - 5455 MiB free\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/mckenziequinn/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q3_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 12\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q3_K:  129 tensors\n",
      "llama_model_loader: - type q4_K:   92 tensors\n",
      "llama_model_loader: - type q5_K:    4 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q3_K - Medium\n",
      "print_info: file size   = 3.28 GiB (3.89 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q3_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/33 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  3355.27 MiB\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 2048\n",
      "llama_init_from_model: n_ctx_per_seq = 2048\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x34124d930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x430fcd0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x34124db60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x430fcd310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x430fcda20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x430fcdc50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x34124dff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x34124e650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x430fcec20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x3414e75f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x3414e7820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x3414e7a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x430fcf440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x34124ecf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x3414e7ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x3414e8220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x34124fb40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x430fcfe60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x341306a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x341306ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x341307120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x430fd05d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x430fd0920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x341307350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x341307800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x341307a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x341307c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x341307e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x3413080c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x430fd0c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x3413082f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x37e37a0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x37e37a9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x341308520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x341308750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x341308980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x341308bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x341308de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x341309010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x341309240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x430fd0fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x3412509f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x341309470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x3413096a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x430fd1450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x430fd2020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x3413098d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x341309b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x341309d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x37e37ac20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x37e37b830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x37e37bdb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x341250c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x341250e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x37e37bfe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x430fd2530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x341309f60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x34130a190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x34130a3c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x430fd2a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x37e37c210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x37e37d020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x34130a5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x34130a820 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x37e37c8a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x37e37d750 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x34130aa50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x341251260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x341251fd0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x34130ac80 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x34130aeb0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x34130b0e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x34130b310 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x430fd2ff0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x34130b540 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x34130b770 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x37e37dea0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x37e37e0d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x34130b9a0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x37e37e300 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x37e37cad0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x341252200 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x37e68a570 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x430fd35e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x430fd3b30 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x430fd4080 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x34130bbd0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x34130be00 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x34130c030 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x34130c260 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x34130c490 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x37e37f1b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x430fd43d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x430fd46e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x34130c6c0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x34130c8f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x34130cb20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x430fd4c60 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x34130cd50 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x34130cf80 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x34130d1b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x34130d3e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x430fd55b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x430fd57e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x430fd6050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x341252ad0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x34130d610 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x430fd6590 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x430fd6a30 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x430fd6e40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x430fd72c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x34130d840 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x34130dd20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x34130e2a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x430fd74f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x430fd7ff0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x37e37fbc0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x430fd8500 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x37e3807d0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x34130e4d0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x34130e700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x34130efc0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x34130f1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x34130fdd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x430fd8910 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x341310000 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x37e380c40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x341310230 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x341310460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x37e381830 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x3412531e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x430fd8c90 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x341310690 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x37e3812a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x341311290 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x3413114c0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x3413116f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x341312360 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x341312590 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x430fd9630 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x430fd9960 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x430fd9b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x430fd9dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x430fd9ff0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x341253410 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x37e3822b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x341253b20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x37e3827c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x3413127c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x341254000 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x430fdafa0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x341312eb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x430fdb5f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x341313350 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x430fdba90 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x3413138a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x3413142d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x341313bb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x341313de0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x341315620 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x341315850 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x341316480 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x3413166b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x3413168e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x341316b10 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x37e382f50 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x37e383180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x341254680 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x3412548b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x341254d10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x341316ee0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x430fdc360 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x3413172f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x341317520 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x341317750 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x37e3837e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x3413189f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x341318c20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x341254f40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x430fdcd90 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x341255d80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x37e384150 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x37e384380 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x341318e50 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x37e3848e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x37e384b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x3412561c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x430fdc730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x341256660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x341256b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x341319590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x3413197c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x430fdd5b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x3413199f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x34131a2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x37e385570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x34131a8b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x34131b510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x37e3857a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x34131b740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x34131bfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x34131c1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x430fddd10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x430fde2e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x34131ce70 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x34131c400 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x37e386200 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x37e386b90 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x37e386dc0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x3412570b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x3412575c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x34131c630 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x34131db50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x34131df60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x34131e190 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x34131e3c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x34131f260 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x34131fb50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x430fde900 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x430fdec60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x430fdee90 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x34131f510 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x3413202e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x430fdf0c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x341320c70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x341320510 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x341320740 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x430fdff30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x341322630 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x341257cf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x341321fd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x341322bd0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x430fe0440 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x430fe0950 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x341258160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x37e387b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x37e387d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x341322e00 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x3413234d0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x341323700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x37e388040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x341323030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x37e388bf0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x37e388310 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x37e388540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x37e38a9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x3413243a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x3413245d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x37e38abf0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x3412586e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x430fe0f70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x37e38ae20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x3412589f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x341324b50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x37e38b050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x341258c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x430fe1520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x341259830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x341259a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x430fe1870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x37e38b710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x34125a050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x34125a4d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x37f07d3d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x430fe2170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x430fe2900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x430fe2da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x34125a950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x430fe31b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x341325230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x153604310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x341325b90 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init: kv_size = 2048, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_init_from_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 514 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '12', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8884.26 ms /    63 tokens (  141.02 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =  197435.59 ms /    38 runs   ( 5195.67 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  206363.73 ms /   101 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 382 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   16091.94 ms /   382 tokens (   42.13 ms per token,    23.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =  136253.58 ms /    26 runs   ( 5240.52 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  152379.69 ms /   408 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 345 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Battery_Type': 'aa', 'Count': '100'}\n",
      "{'Brand': 'Energizer', 'Battery_Type': 'Alkaline', 'Count': '100'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   15440.75 ms /   345 tokens (   44.76 ms per token,    22.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =  219356.72 ms /    41 runs   ( 5350.16 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  234857.49 ms /   386 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 102 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    9445.62 ms /   102 tokens (   92.60 ms per token,    10.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =  382335.39 ms /    75 runs   ( 5097.81 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  391848.50 ms /   177 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 397 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12909.00 ms /   397 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =  128200.52 ms /    26 runs   ( 4930.79 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  141132.58 ms /   423 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 376 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Battery_Type': 'aa', 'Count': '100'}\n",
      "{'Brand': 'IMPECCA', 'Series': 'Platinum Series', 'Battery_Type': 'Alkaline', 'Battery_Voltage': 'Double A', 'Count': '100', 'Packaging': '100-Count'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12054.04 ms /   376 tokens (   32.06 ms per token,    31.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =  158038.34 ms /    33 runs   ( 4789.04 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  170122.37 ms /   409 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 105 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8299.49 ms /   105 tokens (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =  474688.04 ms /    99 runs   ( 4794.83 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  483074.75 ms /   204 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 370 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON response from LLaMA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12177.74 ms /   370 tokens (   32.91 ms per token,    30.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   70446.47 ms /    15 runs   ( 4696.43 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   82638.67 ms /   385 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 308 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': '100'}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12164.07 ms /   308 tokens (   39.49 ms per token,    25.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =  148885.65 ms /    30 runs   ( 4962.85 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  161075.09 ms /   338 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7337.32 ms /    45 tokens (  163.05 ms per token,     6.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =  139645.15 ms /    29 runs   ( 4815.35 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  147007.20 ms /    74 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 75 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8977.59 ms /    75 tokens (  119.70 ms per token,     8.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =  196739.90 ms /    41 runs   ( 4798.53 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  205751.14 ms /   116 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 377 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12252.52 ms /   377 tokens (   32.50 ms per token,    30.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =  131092.49 ms /    25 runs   ( 5243.70 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  143375.25 ms /   402 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 348 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'aa', 'Packaging': {'Count': 100}}\n",
      "{'Brand': 'Amazon Basics', 'Packaging': {'Type': 'Value Pack', 'Count': '100'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11670.57 ms /   348 tokens (   33.54 ms per token,    29.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =  236800.59 ms /    48 runs   ( 4933.35 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  248516.72 ms /   396 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 58 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8087.18 ms /    58 tokens (  139.43 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =  240377.14 ms /    49 runs   ( 4905.66 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  248506.40 ms /   107 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 390 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13515.33 ms /   390 tokens (   34.65 ms per token,    28.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =  123074.12 ms /    26 runs   ( 4733.62 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  136611.33 ms /   416 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 355 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Battery_Type': 'aa', 'Count': '100'}\n",
      "{'Brand': 'Rayovac', 'Battery_Type': 'Alkaline', 'Battery_Voltage': 'Double A', 'Count': 60}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13125.74 ms /   355 tokens (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =  203815.24 ms /    41 runs   ( 4971.10 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  216973.14 ms /   396 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7099.28 ms /    55 tokens (  129.08 ms per token,     7.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =   32947.37 ms /     7 runs   ( 4706.77 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   40053.99 ms /    62 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 77 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7632.41 ms /    77 tokens (   99.12 ms per token,    10.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =  432607.12 ms /    87 runs   ( 4972.50 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  440311.14 ms /   164 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 397 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12985.73 ms /   397 tokens (   32.71 ms per token,    30.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =  176313.95 ms /    36 runs   ( 4897.61 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  189329.84 ms /   433 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 392 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type': 'Batteries', 'Battery_Type': 'AA', 'Capacity': '100'}\n",
      "{'Brand': 'Energizer', 'Type': 'AA', 'Battery_Type': 'Alkaline', 'Capacity': '100 Count', 'Made_in': 'USA', 'Expiration_Date': {'Month': '12', 'Year': '2024'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13061.21 ms /   392 tokens (   33.32 ms per token,    30.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =  201854.02 ms /    41 runs   ( 4923.27 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  214949.79 ms /   433 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 79 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7647.91 ms /    79 tokens (   96.81 ms per token,    10.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =  342424.80 ms /    70 runs   ( 4891.78 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  350129.33 ms /   149 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 398 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   14495.48 ms /   398 tokens (   36.42 ms per token,    27.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =  119847.04 ms /    25 runs   ( 4793.88 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  134370.28 ms /   423 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 372 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'aa', 'Quantity': '100'}\n",
      "{'Brand': 'ACDelco', 'Quantity': '100', 'Battery_Type': 'AA', 'Battery_Type_Description': 'Maximum Power Super Alkaline', 'Shelf_Life': '10-Year'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12424.40 ms /   372 tokens (   33.40 ms per token,    29.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =  201284.98 ms /    42 runs   ( 4792.50 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  213744.65 ms /   414 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 77 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7784.42 ms /    77 tokens (  101.10 ms per token,     9.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =  301753.45 ms /    62 runs   ( 4866.99 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  309589.13 ms /   139 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 392 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13450.18 ms /   392 tokens (   34.31 ms per token,    29.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =  180156.02 ms /    36 runs   ( 5004.33 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  193643.43 ms /   428 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 373 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type': 'Batteries', 'Count': '100', 'Battery_Type': 'aa'}\n",
      "{'Brand': 'Amazon Basics', 'Type': 'AAA', 'Count': '100', 'Battery_Type': 'Alkaline', 'Shelf_Life': '10-Year'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12123.53 ms /   373 tokens (   32.50 ms per token,    30.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =  205605.55 ms /    42 runs   ( 4895.37 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  217760.56 ms /   415 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7967.33 ms /    55 tokens (  144.86 ms per token,     6.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =   47931.60 ms /    10 runs   ( 4793.16 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   55911.49 ms /    65 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 76 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7705.23 ms /    76 tokens (  101.38 ms per token,     9.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =  281955.24 ms /    58 runs   ( 4861.30 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  289707.69 ms /   134 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 394 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13390.75 ms /   394 tokens (   33.99 ms per token,    29.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =  230455.05 ms /    48 runs   ( 4801.15 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  243886.55 ms /   442 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 378 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brand': 'dewalt', 'type': 'cordless screwdriver', 'voltage': '8v', 'size': None, 'condition': None}\n",
      "{'brand': 'DEWALT', 'voltage': '12V MAX', 'type': 'cordless screwdriver', 'size': '1/4-inch', 'condition': 'Tool Only'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11761.89 ms /   378 tokens (   31.12 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =  366074.43 ms /    75 runs   ( 4880.99 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  377907.34 ms /   453 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7606.21 ms /    82 tokens (   92.76 ms per token,    10.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =   96001.95 ms /    20 runs   ( 4800.10 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  103628.07 ms /   102 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 104 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8395.94 ms /   104 tokens (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =  479310.08 ms /    99 runs   ( 4841.52 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  487798.77 ms /   203 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 379 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON response from LLaMA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12296.28 ms /   379 tokens (   32.44 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =  155249.19 ms /    32 runs   ( 4851.54 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  167572.29 ms /   411 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 323 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'DeWalt', 'Product_Type': 'Cordless Screwdriver Kit'}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11593.09 ms /   323 tokens (   35.89 ms per token,    27.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =  212631.26 ms /    45 runs   ( 4725.14 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  224257.77 ms /   368 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7074.83 ms /    58 tokens (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =  139806.04 ms /    29 runs   ( 4820.90 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  146902.84 ms /    87 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 86 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8267.60 ms /    86 tokens (   96.13 ms per token,    10.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =  478311.19 ms /    99 runs   ( 4831.43 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  486663.60 ms /   185 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 379 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON response from LLaMA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11892.83 ms /   379 tokens (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =  166238.76 ms /    32 runs   ( 5194.96 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  178161.86 ms /   411 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 323 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'DeWalt', 'Product_Type': 'Cordless Screwdriver Kit'}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11329.85 ms /   323 tokens (   35.08 ms per token,    28.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =  214590.17 ms /    45 runs   ( 4768.67 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  225959.60 ms /   368 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7154.69 ms /    58 tokens (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =  138886.79 ms /    29 runs   ( 4789.20 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  146063.19 ms /    87 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 58 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    6971.90 ms /    58 tokens (  120.21 ms per token,     8.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =  263261.67 ms /    53 runs   ( 4967.20 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  270274.12 ms /   111 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 396 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   14020.01 ms /   396 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =  191083.60 ms /    40 runs   ( 4777.09 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  205133.88 ms /   436 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 370 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'dewalt', 'Type': 'cordless screwdriver kit', 'Battery_Type': '8v max'}\n",
      "{'Brand': 'DEWALT', 'Type': 'Battery Charger', 'Voltage': '8V MAX', 'Battery_Type': 'Not specified in title'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12011.68 ms /   370 tokens (   32.46 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =  336207.13 ms /    70 runs   ( 4802.96 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  348276.93 ms /   440 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7781.96 ms /    79 tokens (   98.51 ms per token,    10.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =   56745.04 ms /    12 runs   ( 4728.75 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   64538.22 ms /    91 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 75 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7843.07 ms /    75 tokens (  104.57 ms per token,     9.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =  342572.11 ms /    71 runs   ( 4824.96 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  350471.71 ms /   146 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 403 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13143.35 ms /   403 tokens (   32.61 ms per token,    30.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =  187879.99 ms /    37 runs   ( 5077.84 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  201056.02 ms /   440 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 382 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'dewalt', 'Type': 'cordless screwdriver', 'Power Source': '8v max'}\n",
      "{'Brand': 'DEWALT', 'Type': 'Cordless Screwdriver Kit', 'Power Source': '8V MAX', 'Features': ['Gyroscopic'], 'Batteries Included': True, 'Quantity': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12624.30 ms /   382 tokens (   33.05 ms per token,    30.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =  278618.70 ms /    57 runs   ( 4888.05 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  291293.00 ms /   439 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8056.10 ms /    68 tokens (  118.47 ms per token,     8.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   66435.01 ms /    14 runs   ( 4745.36 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   74505.06 ms /    82 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 74 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7492.90 ms /    74 tokens (  101.26 ms per token,     9.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =  376330.02 ms /    77 runs   ( 4887.40 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  383887.78 ms /   151 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 402 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13471.29 ms /   402 tokens (   33.51 ms per token,    29.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =  349709.93 ms /    73 runs   ( 4790.55 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  363246.29 ms /   475 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 419 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'cordless screwdriver', 'brand': 'dewalt', 'model': '8v max cordless screwdriver kit', 'voltage': '8V', 'batteries_included': True, 'features': ['gyroscopic']}\n",
      "{'brand': 'DEWALT', 'model': 'DCF682N1', 'type': 'Cordless Screwdriver Kit', 'voltage': '8V MAX', 'batteries_included': True, 'features': ['Gyroscopic']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   16845.36 ms /   419 tokens (   40.20 ms per token,    24.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =  436477.41 ms /    88 runs   ( 4959.97 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  453397.48 ms /   507 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 88 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7640.27 ms /    88 tokens (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =  194723.96 ms /    38 runs   ( 5124.31 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  202398.70 ms /   126 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 385 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13480.98 ms /   385 tokens (   35.02 ms per token,    28.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =  190710.77 ms /    40 runs   ( 4767.77 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  204219.89 ms /   425 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 353 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'Kodak', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'Kodak', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12222.31 ms /   353 tokens (   34.62 ms per token,    28.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =  268695.27 ms /    55 runs   ( 4885.37 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  280963.17 ms /   408 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 88 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8029.97 ms /    88 tokens (   91.25 ms per token,    10.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =  263709.16 ms /    52 runs   ( 5071.33 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  271779.39 ms /   140 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 390 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13116.40 ms /   390 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =  198707.11 ms /    41 runs   ( 4846.51 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  211856.42 ms /   431 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 366 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'photo paper', 'Size': {'Width': '8.5', 'Height': '11'}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Size': {'Width': '8.5 inches', 'Length': '11 inches'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12163.07 ms /   366 tokens (   33.23 ms per token,    30.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =  271995.91 ms /    56 runs   ( 4857.07 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  284203.72 ms /   422 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 73 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7580.23 ms /    73 tokens (  103.84 ms per token,     9.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =  302035.24 ms /    62 runs   ( 4871.54 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  309675.22 ms /   135 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 392 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13051.51 ms /   392 tokens (   33.29 ms per token,    30.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =  189665.90 ms /    38 runs   ( 4991.21 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  202751.66 ms /   430 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 371 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'material': 'photo paper', 'size': {'width': 8.5, 'height': 11}}\n",
      "{'material': 'Photo Paper', 'thickness': '6.5 mil', 'finish': 'Glossy', 'size': {'width': '8-1/2', 'length': '11'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13391.01 ms /   371 tokens (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =  274511.33 ms /    56 runs   ( 4901.99 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  287953.20 ms /   427 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8100.56 ms /    65 tokens (  124.62 ms per token,     8.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   53590.96 ms /    11 runs   ( 4871.91 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   61701.70 ms /    76 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 83 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7840.33 ms /    83 tokens (   94.46 ms per token,    10.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =  433746.42 ms /    90 runs   ( 4819.40 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  441659.83 ms /   173 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 402 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13210.77 ms /   402 tokens (   32.86 ms per token,    30.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =  187785.70 ms /    38 runs   ( 4941.73 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  201023.45 ms /   440 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 395 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type': 'Photo Paper', 'Size': {'Width': 11, 'Height': 8.5}}\n",
      "{'Brand': 'Kodak', 'Product_Code': '8209017', 'Type': 'Photo Paper', 'Thickness': '6.5 mil', 'Finish': 'Glossy', 'Size': {'Width': '8-1/2', 'Length': '11'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13280.58 ms /   395 tokens (   33.62 ms per token,    29.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =  258808.84 ms /    53 runs   ( 4883.19 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  272133.16 ms /   448 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 86 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7663.30 ms /    86 tokens (   89.11 ms per token,    11.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =  344302.45 ms /    70 runs   ( 4918.61 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  352027.79 ms /   156 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 399 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12882.40 ms /   399 tokens (   32.29 ms per token,    30.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =  193935.39 ms /    40 runs   ( 4848.38 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  206849.03 ms /   439 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 379 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'Photo Paper', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Finish': 'Gloss', 'Thickness': '7 mil', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12614.04 ms /   379 tokens (   33.28 ms per token,    30.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =  210601.04 ms /    43 runs   ( 4897.70 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  223260.09 ms /   422 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 94 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7785.36 ms /    94 tokens (   82.82 ms per token,    12.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =  351618.00 ms /    73 runs   ( 4816.68 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  359467.58 ms /   167 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 399 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13883.11 ms /   399 tokens (   34.79 ms per token,    28.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =  198774.59 ms /    40 runs   ( 4969.36 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  212690.40 ms /   439 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 382 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'Photo Paper', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Finish': 'Gloss', 'Thickness': '10.7 mil', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11793.09 ms /   382 tokens (   30.87 ms per token,    32.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =  150066.61 ms /    31 runs   ( 4840.86 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  161888.88 ms /   413 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 90 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7561.97 ms /    90 tokens (   84.02 ms per token,    11.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =  348552.45 ms /    72 runs   ( 4841.01 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  356180.19 ms /   162 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 399 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12808.24 ms /   399 tokens (   32.10 ms per token,    31.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =  205751.42 ms /    40 runs   ( 5143.79 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  218596.55 ms /   439 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 381 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'Photo Paper', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Finish': 'Gloss', 'Thickness': '8.5 mil', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11838.51 ms /   381 tokens (   31.07 ms per token,    32.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =  148657.73 ms /    31 runs   ( 4795.41 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  160524.71 ms /   412 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 86 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    8934.81 ms /    86 tokens (  103.89 ms per token,     9.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =  358898.00 ms /    70 runs   ( 5127.11 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  367896.11 ms /   156 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 399 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   12949.37 ms /   399 tokens (   32.45 ms per token,    30.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =  196228.82 ms /    41 runs   ( 4786.07 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  209209.80 ms /   440 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 380 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'Photo Paper', 'Size': {'Width': '8.5', 'Height': '11'}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Finish': 'Matte', 'Thickness': '7 mil', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11525.09 ms /   380 tokens (   30.33 ms per token,    32.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =  150943.82 ms /    31 runs   ( 4869.16 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  162497.88 ms /   411 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 92 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =    7920.22 ms /    92 tokens (   86.09 ms per token,    11.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =  346702.34 ms /    72 runs   ( 4815.31 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time =  354687.74 ms /   164 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 399 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   13168.41 ms /   399 tokens (   33.00 ms per token,    30.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =  211307.08 ms /    40 runs   ( 5282.68 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  224526.72 ms /   439 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 381 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product_Type': 'photo paper', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'Kodak', 'Product_Type': 'Photo Paper', 'Finish': 'Gloss', 'Thickness': '8.5 mil', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   18009.30 ms /   381 tokens (   47.27 ms per token,    21.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =  170644.81 ms /    31 runs   ( 5504.67 ms per token,     0.18 tokens per second)\n",
      "llama_perf_context_print:       total time =  188702.09 ms /   412 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 99 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   11571.49 ms /    99 tokens (  116.88 ms per token,     8.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =  202114.08 ms /    38 runs   ( 5318.79 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  213745.19 ms /   137 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 385 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   16239.54 ms /   385 tokens (   42.18 ms per token,    23.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =  218391.79 ms /    40 runs   ( 5459.79 ms per token,     0.18 tokens per second)\n",
      "llama_perf_context_print:       total time =  234680.35 ms /   425 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 353 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brand': 'Kodak', 'Size': {'Width': 8.5, 'Height': 11}}\n",
      "{'Brand': 'KODAK', 'Size': {'Width': 8.5, 'Length': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    8884.82 ms\n",
      "llama_perf_context_print: prompt eval time =   15300.29 ms /   353 tokens (   43.34 ms per token,    23.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =  293476.37 ms /    55 runs   ( 5335.93 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  308843.07 ms /   408 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "## takes roughly ~260 min \n",
    "df_results = utils.main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 7 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   37611.35 ms\n",
      "llama_perf_context_print: prompt eval time =    9536.15 ms /    84 tokens (  113.53 ms per token,     8.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =  273054.53 ms /    52 runs   ( 5251.05 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  282672.12 ms /   136 tokens\n",
      "Llama.generate: 7 prefix-match hit, remaining 390 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   37611.35 ms\n",
      "llama_perf_context_print: prompt eval time =   18923.34 ms /   390 tokens (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =  219630.37 ms /    41 runs   ( 5356.84 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  238610.18 ms /   431 tokens\n"
     ]
    }
   ],
   "source": [
    "# text = 'Kodak photo paper 8.5 x 11 matte, 100 count 39 lb - 145 g/m (41164-8318164)'\n",
    "# query = 'kodak photo paper 8.5 x 11 glossy'\n",
    "# product_attributes = utils.json_parse(utils.extract_product_attributes(llm, text))\n",
    "# query_attributes = utils.json_parse(utils.extract_query_attributes(llm, query, list(product_attributes.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Product_Type': 'photo paper', 'Size': {'Width': '8.5', 'Height': '11'}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brand': 'Kodak',\n",
       " 'Product_Type': 'Photo Paper',\n",
       " 'Size': {'Width': '8.5 inches', 'Length': '11 inches'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 366 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   37611.35 ms\n",
      "llama_perf_context_print: prompt eval time =   16324.34 ms /   366 tokens (   44.60 ms per token,    22.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =  298617.46 ms /    56 runs   ( 5332.45 ms per token,     0.19 tokens per second)\n",
      "llama_perf_context_print:       total time =  315024.72 ms /   422 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'satisfied': True,\n",
       " 'fixed_query': {'Product_Type': 'photo paper',\n",
       "  'Size': {'Width': '8.5', 'Height': '11'}}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.json_parse(utils.compare_jsons(llm, query_attributes, product_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>corrected_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6014</td>\n",
       "      <td>B01G1RYHAO</td>\n",
       "      <td>True</td>\n",
       "      <td>aa batteries 100 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6014</td>\n",
       "      <td>B07FP5DNBG</td>\n",
       "      <td>True</td>\n",
       "      <td>aa batteries 100 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6014</td>\n",
       "      <td>B07F7RH8D4</td>\n",
       "      <td>False</td>\n",
       "      <td>100 items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6014</td>\n",
       "      <td>B01B8R6PF2</td>\n",
       "      <td>True</td>\n",
       "      <td>aa batteries 100 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6014</td>\n",
       "      <td>B00LHSAARW</td>\n",
       "      <td>False</td>\n",
       "      <td>60 Alkaline batteries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6014</td>\n",
       "      <td>B00KMDL8U6</td>\n",
       "      <td>True</td>\n",
       "      <td>aa batteries 100 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6014</td>\n",
       "      <td>B004SCA15K</td>\n",
       "      <td>True</td>\n",
       "      <td>aa batteries 100 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6014</td>\n",
       "      <td>B01B8R6V2E</td>\n",
       "      <td>False</td>\n",
       "      <td>AAA Alkaline battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32814</td>\n",
       "      <td>B07TWK2S22</td>\n",
       "      <td>False</td>\n",
       "      <td>12V MAX DEWALT cordless 1/4-inch screwdriver T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32814</td>\n",
       "      <td>B0812ZHY5N</td>\n",
       "      <td>False</td>\n",
       "      <td>cordless drill DeWalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32814</td>\n",
       "      <td>B07S7F53YK</td>\n",
       "      <td>False</td>\n",
       "      <td>cordless drill DeWalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32814</td>\n",
       "      <td>B00EUHAGX0</td>\n",
       "      <td>False</td>\n",
       "      <td>8V MAX DEWALT Battery Charger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32814</td>\n",
       "      <td>B00DL7QDS2</td>\n",
       "      <td>False</td>\n",
       "      <td>8V MAX DEWALT Cordless Screwdriver Kit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32814</td>\n",
       "      <td>B011WRUODC</td>\n",
       "      <td>True</td>\n",
       "      <td>dewalt 8v max cordless screwdriver kit, gyrosc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58953</td>\n",
       "      <td>B085G3MGFR</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58953</td>\n",
       "      <td>B085F42SV6</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58953</td>\n",
       "      <td>B01M0L2WLF</td>\n",
       "      <td>False</td>\n",
       "      <td>8-1/2 x 11 Photo Paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58953</td>\n",
       "      <td>B01JB7D4SW</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EZTYHG</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EZTYG2</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EZTYCG</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EZ0CTK</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EYAKKW</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58953</td>\n",
       "      <td>B000EYAKJS</td>\n",
       "      <td>True</td>\n",
       "      <td>kodak photo paper 8.5 x 11 glossy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id  product_id  is_correct  \\\n",
       "0       6014  B01G1RYHAO        True   \n",
       "1       6014  B07FP5DNBG        True   \n",
       "2       6014  B07F7RH8D4       False   \n",
       "3       6014  B01B8R6PF2        True   \n",
       "4       6014  B00LHSAARW       False   \n",
       "5       6014  B00KMDL8U6        True   \n",
       "6       6014  B004SCA15K        True   \n",
       "7       6014  B01B8R6V2E       False   \n",
       "8      32814  B07TWK2S22       False   \n",
       "9      32814  B0812ZHY5N       False   \n",
       "10     32814  B07S7F53YK       False   \n",
       "11     32814  B00EUHAGX0       False   \n",
       "12     32814  B00DL7QDS2       False   \n",
       "13     32814  B011WRUODC        True   \n",
       "14     58953  B085G3MGFR        True   \n",
       "15     58953  B085F42SV6        True   \n",
       "16     58953  B01M0L2WLF       False   \n",
       "17     58953  B01JB7D4SW        True   \n",
       "18     58953  B000EZTYHG        True   \n",
       "19     58953  B000EZTYG2        True   \n",
       "20     58953  B000EZTYCG        True   \n",
       "21     58953  B000EZ0CTK        True   \n",
       "22     58953  B000EYAKKW        True   \n",
       "23     58953  B000EYAKJS        True   \n",
       "\n",
       "                                      corrected_query  \n",
       "0                               aa batteries 100 pack  \n",
       "1                               aa batteries 100 pack  \n",
       "2                                           100 items  \n",
       "3                               aa batteries 100 pack  \n",
       "4                              60 Alkaline batteries.  \n",
       "5                               aa batteries 100 pack  \n",
       "6                               aa batteries 100 pack  \n",
       "7                                AAA Alkaline battery  \n",
       "8   12V MAX DEWALT cordless 1/4-inch screwdriver T...  \n",
       "9                               cordless drill DeWalt  \n",
       "10                              cordless drill DeWalt  \n",
       "11                      8V MAX DEWALT Battery Charger  \n",
       "12            8V MAX DEWALT Cordless Screwdriver Kit.  \n",
       "13  dewalt 8v max cordless screwdriver kit, gyrosc...  \n",
       "14                  kodak photo paper 8.5 x 11 glossy  \n",
       "15                  kodak photo paper 8.5 x 11 glossy  \n",
       "16                             8-1/2 x 11 Photo Paper  \n",
       "17                  kodak photo paper 8.5 x 11 glossy  \n",
       "18                  kodak photo paper 8.5 x 11 glossy  \n",
       "19                  kodak photo paper 8.5 x 11 glossy  \n",
       "20                  kodak photo paper 8.5 x 11 glossy  \n",
       "21                  kodak photo paper 8.5 x 11 glossy  \n",
       "22                  kodak photo paper 8.5 x 11 glossy  \n",
       "23                  kodak photo paper 8.5 x 11 glossy  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('../data/valid_dataset.csv')\n",
    "df_results['label'] = df_results['is_correct'].replace({'Yes': 1, 'No': 0, 'Maybe':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(df_valid[' label'], df_results['label'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {'product_extraction':'''\n",
    "    Extract the key product attributes from the given product title. \n",
    "    Return the extracted attributes in a structured JSON format.\n",
    "\n",
    "    Product title: '{text}'\n",
    "    JSON Output:\n",
    "    ''',\n",
    "    'query_extraction':'''\n",
    "    Extract the values corresponding to the given attribute keys from the text. \n",
    "\n",
    "    Follow these strict rules:\n",
    "\n",
    "    1. **Brand Identification**:\n",
    "    - Extract a value for \"Brand\" **only** if the text explicitly contains a known manufacturer or company name.\n",
    "    - **Do not assume or infer a brand** if none is mentioned.\n",
    "    - If the product name resembles a brand but isn't a real one, do not classify it as a brand.\n",
    "\n",
    "    2. **Product Type vs. Other Attributes**:\n",
    "    - Identify product-related attributes (e.g., \"Battery_Type\", \"Material\", \"Size\") correctly.\n",
    "    - If an attribute appears in the text, extract it **exactly as stated**.\n",
    "    - **Do not confuse the product name with its brand**  (e.g., \"AA Batteries\" → \"AA\" is the battery type, NOT the brand).\n",
    "\n",
    "    3. **Numerical Attributes**:\n",
    "    - Extract numbers only when they indicate quantities (e.g., \"Count\", \"Capacity\", \"Weight\").\n",
    "    - Do **not** infer missing numbers; only use explicitly mentioned values.\n",
    "\n",
    "    4. **Strict No-Hallucination Policy**:\n",
    "    - **Only return attributes explicitly stated in the text**.\n",
    "    - **Do not infer missing values** (e.g., do not assume default voltages, materials, or sizes).\n",
    "    - If an attribute is **not present**, exclude it from the output.\n",
    "    \n",
    "      Return the output in JSON format.\n",
    "\n",
    "    Keys: {keys}\n",
    "    Text: '{text}'\n",
    "    JSON Output:\n",
    "    ''',\n",
    "    'compare_json':'''\n",
    "        Compare the following JSON objects and determine if the `product_json` satisfies the `query_json`.\n",
    "\n",
    "        ## **Rules for Satisfaction:**\n",
    "        1. All attributes in `query_json` **must exist** in `product_json` and must **match exactly**.\n",
    "        - **Text values** should be compared **case-insensitively**.\n",
    "        - **Numerical values** should be compared **numerically** (convert strings to numbers if necessary).\n",
    "        2. If **any** value in `query_json` differs from `product_json`, **\"satisfied\" must be false**.\n",
    "        3. If `\"satisfied\": false`, **correct `fixed_query`** by replacing the mismatched values in `query_json` with those from `product_json`.\n",
    "\n",
    "        ### Output Format:\n",
    "        Return a JSON object with the following structure:\n",
    "        {{\n",
    "        \"satisfied\": true or false,\n",
    "        \"fixed_query\": {{ ... }}  \n",
    "        }}\n",
    "        - If `\"satisfied\": true`, `fixed_query` should be identical to `query_json`.\n",
    "        - If `\"satisfied\": false`, fixed_query must contain all original attributes, but mismatched ones replaced with product_json values.\n",
    "        query_json = {query_json}\n",
    "        product_json = {product_json}\n",
    "        response:\n",
    "        ''',\n",
    "    'corrected_query': '''\n",
    "    Generate a concise product search query from the following product attributes.\n",
    "\n",
    "    Corrected Query Dictionary:\n",
    "    {corrected_query_dict}\n",
    "\n",
    "    Output only the search query: \n",
    "    '''}\n",
    "params = {'product_extraction':{'max_tokens':100, 'temperature':0.2, 'stop':['}']},\n",
    "          'query_extraction':{'max_tokens':100, 'temperature':0.2, 'stop':['}']},\n",
    "          'compare_jsons':{'max_tokens':100, 'temperature':0.2, 'stop':['}']},\n",
    "          'corrected_query': {'max_tokens':30, 'temperature':0.2}}\n",
    "description = \"LLM to extract query and prodcut attributes as jsons, then compare JSONs using LLM and use another llm to create corrected query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [accuracy, config.model_path, params, prompts,description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_log = pd.read_csv(config.results_log)\n",
    "    df_log.loc[len(df_log)] = row\n",
    "except: \n",
    "    df_log = pd.DataFrame([row], columns=['accuracy_score', 'model_path', 'inference_params', 'prompt', 'description'])\n",
    "df_log.to_csv(config.results_log, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>model_path</th>\n",
       "      <th>inference_params</th>\n",
       "      <th>prompt</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>/Users/mckenziequinn/.cache/huggingface/hub/mo...</td>\n",
       "      <td>{'max_tokens': 30, 'temperature': 0.2}</td>\n",
       "      <td>\\n   You are a product verification assistant....</td>\n",
       "      <td>LLM straight validation and correction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>/Users/mckenziequinn/.cache/huggingface/hub/mo...</td>\n",
       "      <td>{'attribute_extraction': {'max_tokens': 100, '...</td>\n",
       "      <td>{'attribute_extraction': '\\n    Extract the fo...</td>\n",
       "      <td>LLM to extract query and prodcut attributes as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>/Users/mckenziequinn/.cache/huggingface/hub/mo...</td>\n",
       "      <td>{'attribute_extraction': {'max_tokens': 100, '...</td>\n",
       "      <td>{'attribute_extraction': '\\n    Extract the fo...</td>\n",
       "      <td>LLM to extract query and prodcut attributes as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>/Users/mckenziequinn/.cache/huggingface/hub/mo...</td>\n",
       "      <td>{'product_extraction': {'max_tokens': 100, 'te...</td>\n",
       "      <td>{'product_extraction': '\n",
       "    Extract the key p...</td>\n",
       "      <td>LLM to extract query and prodcut attributes as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score                                         model_path  \\\n",
       "0        0.333333  /Users/mckenziequinn/.cache/huggingface/hub/mo...   \n",
       "1        0.875000  /Users/mckenziequinn/.cache/huggingface/hub/mo...   \n",
       "2        0.750000  /Users/mckenziequinn/.cache/huggingface/hub/mo...   \n",
       "3        0.708333  /Users/mckenziequinn/.cache/huggingface/hub/mo...   \n",
       "\n",
       "                                    inference_params  \\\n",
       "0             {'max_tokens': 30, 'temperature': 0.2}   \n",
       "1  {'attribute_extraction': {'max_tokens': 100, '...   \n",
       "2  {'attribute_extraction': {'max_tokens': 100, '...   \n",
       "3  {'product_extraction': {'max_tokens': 100, 'te...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  \\n   You are a product verification assistant....   \n",
       "1  {'attribute_extraction': '\\n    Extract the fo...   \n",
       "2  {'attribute_extraction': '\\n    Extract the fo...   \n",
       "3  {'product_extraction': '\n",
       "    Extract the key p...   \n",
       "\n",
       "                                         description  \n",
       "0             LLM straight validation and correction  \n",
       "1  LLM to extract query and prodcut attributes as...  \n",
       "2  LLM to extract query and prodcut attributes as...  \n",
       "3  LLM to extract query and prodcut attributes as...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
